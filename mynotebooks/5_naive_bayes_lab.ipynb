{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Naive Bayes Lab - SMS Spam Classification\n",
    "===============\n",
    "orignally developed by Ankit Jain\n",
    "\n",
    "CLASS: Naive Bayes SMS spam classifier using sklearn\n",
    "\n",
    "Data source: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## READING IN THE DATA\n",
    "df = pd.read_csv(\"data/sms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  ham</td>\n",
       "      <td> Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>  ham</td>\n",
       "      <td>                     Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> spam</td>\n",
       "      <td> Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>  ham</td>\n",
       "      <td> U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  ham</td>\n",
       "      <td> Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> spam</td>\n",
       "      <td> FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>  ham</td>\n",
       "      <td> Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>  ham</td>\n",
       "      <td> As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> spam</td>\n",
       "      <td> WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> spam</td>\n",
       "      <td> Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> spam</td>\n",
       "      <td> Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td> spam</td>\n",
       "      <td> FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> spam</td>\n",
       "      <td> WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> spam</td>\n",
       "      <td> Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> spam</td>\n",
       "      <td> SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> spam</td>\n",
       "      <td> URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> spam</td>\n",
       "      <td> XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td> spam</td>\n",
       "      <td> England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td> spam</td>\n",
       "      <td> Thanks for your subscription to Ringtone UK yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td> spam</td>\n",
       "      <td> 07732584351 - Rodger Burns - MSG = We tried to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                msg\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "19  spam  England v Macedonia - dont miss the goals/team...\n",
       "34  spam  Thanks for your subscription to Ringtone UK yo...\n",
       "42  spam  07732584351 - Rodger Burns - MSG = We tried to..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label=='spam'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       5572\n",
       "unique                      5169\n",
       "top       Sorry, I'll call later\n",
       "freq                          30\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.msg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the label into a binary variable\n",
    "# Remember the map function we learned before?\n",
    "df['label'] = df.label.map({'ham': 0 , 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0</td>\n",
       "      <td>                     Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0</td>\n",
       "      <td> U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                msg\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets by calling sklearn lib\n",
    "# by default, the data set is split into 0.75 (training) and 0.25 (testing)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.msg, df.label, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179,)\n",
      "[ '4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths+? Call MobilesDirect free on 08000938767 to update now! or2stoptxt T&Cs'\n",
      " 'Did you stitch his trouser'\n",
      " 'Hope you enjoyed your new content. text stop to 61610 to unsubscribe. help:08712400602450p Provided by tones2you.co.uk'\n",
      " ...,\n",
      " 'CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C YA 2MORO! WHO NEEDS BLOKES'\n",
      " 'Text & meet someone sexy today. U can find a date or even flirt its up to U. Join 4 just 10p. REPLY with NAME & AGE eg Sam 25. 18 -msg recd@thirtyeight pence'\n",
      " 'K k:) sms chat with me.']\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "#print len(X_train)\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the text into feature vectors which can be used for machine learning purposes.\n",
    "We will use the scikit function of CountVectorizer to 'convert text into a matrix of token counts'\n",
    "\n",
    " http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start with a simple example\n",
    "train_simple = ['call you tonight',\n",
    "                'Call me a cab',\n",
    "                'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cab', u'call', u'me', u'please', u'tonight', u'you']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(train_simple)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "train_simple_dtm = vect.transform(train_simple)\n",
    "train_simple_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(train_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "test_simple = [\"please don't call me\"]\n",
    "test_simple_dtm = vect.transform(test_simple)\n",
    "test_simple_dtm.toarray()\n",
    "pd.DataFrame(test_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
       "        charset_error=None, decode_error='ignore',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the vectorizer ( use variable name as vect)\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(X_train)\n",
    "#vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1538)\t1\n",
      "  (0, 5196)\t1\n",
      "  (0, 6551)\t1\n",
      "  (0, 7416)\t1\n",
      "  (1, 1016)\t1\n",
      "  (1, 3055)\t1\n",
      "  (1, 4167)\t1\n",
      "  (1, 4243)\t1\n",
      "  (1, 4375)\t1\n",
      "  (1, 5207)\t1\n",
      "  (1, 6665)\t1\n",
      "  (1, 7418)\t1\n",
      "  (1, 7431)\t1\n",
      "  (2, 986)\t1\n",
      "  (2, 3249)\t1\n",
      "  (2, 7173)\t1\n",
      "  (3, 3242)\t1\n",
      "  (4, 887)\t2\n",
      "  (4, 1060)\t1\n",
      "  (4, 1596)\t1\n",
      "  (4, 2070)\t1\n",
      "  (4, 2838)\t1\n",
      "  (4, 3394)\t1\n",
      "  (4, 3629)\t1\n",
      "  (4, 3926)\t1\n",
      "  :\t:\n",
      "  (1391, 4378)\t1\n",
      "  (1391, 4418)\t1\n",
      "  (1391, 4446)\t1\n",
      "  (1391, 4749)\t1\n",
      "  (1391, 4784)\t1\n",
      "  (1391, 6026)\t1\n",
      "  (1391, 6066)\t1\n",
      "  (1391, 6840)\t1\n",
      "  (1391, 6915)\t1\n",
      "  (1391, 7023)\t1\n",
      "  (1391, 7131)\t1\n",
      "  (1391, 7241)\t2\n",
      "  (1391, 7250)\t1\n",
      "  (1391, 7298)\t1\n",
      "  (1391, 7368)\t1\n",
      "  (1392, 848)\t1\n",
      "  (1392, 2404)\t1\n",
      "  (1392, 2878)\t1\n",
      "  (1392, 3163)\t1\n",
      "  (1392, 4243)\t1\n",
      "  (1392, 4260)\t2\n",
      "  (1392, 4492)\t1\n",
      "  (1392, 4808)\t1\n",
      "  (1392, 5573)\t1\n",
      "  (1392, 7086)\t1\n"
     ]
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix: Use Variable name as test_dtm\n",
    "train_dtm = vect.transform(X_train)\n",
    "test_dtm = vect.transform(X_test)\n",
    "print test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7465"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the length  and names of the feature names\n",
    "train_features = vect.get_feature_names()\n",
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00',\n",
       " u'000',\n",
       " u'008704050406',\n",
       " u'0121',\n",
       " u'01223585236',\n",
       " u'01223585334',\n",
       " u'0125698789',\n",
       " u'02',\n",
       " u'0207',\n",
       " u'02072069400',\n",
       " u'02073162414',\n",
       " u'02085076972',\n",
       " u'021',\n",
       " u'03',\n",
       " u'04',\n",
       " u'0430',\n",
       " u'05',\n",
       " u'050703',\n",
       " u'0578',\n",
       " u'06',\n",
       " u'07',\n",
       " u'07008009200',\n",
       " u'07090201529',\n",
       " u'07090298926',\n",
       " u'07123456789',\n",
       " u'07732584351',\n",
       " u'07734396839',\n",
       " u'07742676969',\n",
       " u'0776xxxxxxx',\n",
       " u'07781482378',\n",
       " u'07786200117',\n",
       " u'078',\n",
       " u'07801543489',\n",
       " u'07808',\n",
       " u'07808247860',\n",
       " u'07808726822',\n",
       " u'07815296484',\n",
       " u'07821230901',\n",
       " u'07880867867',\n",
       " u'0789xxxxxxx',\n",
       " u'07946746291',\n",
       " u'0796xxxxxx',\n",
       " u'07973788240',\n",
       " u'07xxxxxxxxx',\n",
       " u'08',\n",
       " u'0800',\n",
       " u'08000407165',\n",
       " u'08000776320',\n",
       " u'08000839402',\n",
       " u'08000930705']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'yeovil',\n",
       " u'yep',\n",
       " u'yer',\n",
       " u'yes',\n",
       " u'yest',\n",
       " u'yesterday',\n",
       " u'yet',\n",
       " u'yetunde',\n",
       " u'yijue',\n",
       " u'ym',\n",
       " u'ymca',\n",
       " u'yo',\n",
       " u'yoga',\n",
       " u'yogasana',\n",
       " u'yor',\n",
       " u'yorge',\n",
       " u'you',\n",
       " u'youdoing',\n",
       " u'youi',\n",
       " u'youphone',\n",
       " u'your',\n",
       " u'youre',\n",
       " u'yourjob',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'youwanna',\n",
       " u'yowifes',\n",
       " u'yoyyooo',\n",
       " u'yr',\n",
       " u'yrs',\n",
       " u'ything',\n",
       " u'yummmm',\n",
       " u'yummy',\n",
       " u'yun',\n",
       " u'yunny',\n",
       " u'yuo',\n",
       " u'yuou',\n",
       " u'yup',\n",
       " u'zac',\n",
       " u'zaher',\n",
       " u'zealand',\n",
       " u'zebra',\n",
       " u'zed',\n",
       " u'zeros',\n",
       " u'zhong',\n",
       " u'zindgi',\n",
       " u'zoe',\n",
       " u'zoom',\n",
       " u'zouk',\n",
       " u'zyada']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert train_dtm to a regular array\n",
    "train_arr = train_dtm.toarray()\n",
    "train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "[1 2 3 4]\n",
      "[1 5]\n",
      "36\n",
      "[ 6  8 10 12]\n",
      "[10 26]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Revisit Numpy\n",
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print arr[0, 0]\n",
    "print arr[1, 3]\n",
    "print arr[0, :]\n",
    "print arr[:, 0]\n",
    "print np.sum(arr)\n",
    "print np.sum(arr,axis = 0)\n",
    "print np.sum(arr,axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# exercise: calculate the number of tokens in the 0th message in train_arr\n",
    "print np.sum(train_arr[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# exercise: count how many times the 0th token appears across ALL messages in train_arr\n",
    "print np.sum(train_arr[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 23  2 ...,  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# exercise: count how many times EACH token appears across ALL messages in train_arr\n",
    "print np.sum(train_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: create a DataFrame of tokens with their counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the model with Naive Bayes Now\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a Naive Bayes model using train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on test data using test_dtm\n",
    "preds = nb.predict(test_dtm)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987796123475\n",
      "[[1203    5]\n",
      " [  12  173]]\n"
     ]
    }
   ],
   "source": [
    "# compare predictions to true labels\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, preds)\n",
    "print metrics.confusion_matrix(y_test, preds)\n",
    "# confusion matrix: http://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Waiting for your call.', 'Also andros ice etc etc',\n",
       "       'No calls..messages..missed calls', 'No pic. Please re-send.',\n",
       "       'No calls..messages..missed calls'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise: show the message text for the false positives\n",
    "X_test[(y_test == 0) & (preds == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ \"LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\",\n",
       "       \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, \\xe5\\xa31.50 to rcv\",\n",
       "       \"Xmas & New Years Eve tickets are now on sale from the club, during the day from 10am till 8pm, and on Thurs, Fri & Sat night this week. They're selling fast!\",\n",
       "       \"Hi I'm sue. I am 20 years old and work as a lapdancer. I love sex. Text me live - I'm i my bedroom now. text SUE to 89555. By TextOperator G2 1DA 150ppmsg 18+\",\n",
       "       'Would you like to see my XXX pics they are so hot they were nearly banned in the uk!',\n",
       "       'CALL 09090900040 & LISTEN TO EXTREME DIRTY LIVE CHAT GOING ON IN THE OFFICE RIGHT NOW TOTAL PRIVACY NO ONE KNOWS YOUR [sic] LISTENING 60P MIN 24/7MP 0870753331018+',\n",
       "       'thesmszone.com lets you send free anonymous and masked messages..im sending this message from there..do you see the potential for abuse???',\n",
       "       'Hi this is Amy, we will be sending you a free phone number in a couple of days, which will give you an access to all the adult parties...',\n",
       "       \"INTERFLORA - \\xe5\\xd2It's not too late to order Interflora flowers for christmas call 0800 505060 to place your order before Midnight tomorrow.\",\n",
       "       \"You won't believe it but it's true. It's Incredible Txts! Reply G now to learn truly amazing things that will blow your mind. From O2FWD only 18p/txt\",\n",
       "       \"Hi ya babe x u 4goten bout me?' scammers getting smart..Though this is a regular vodafone no, if you respond you get further prem rate msg/subscription. Other nos used also. Beware!\",\n",
       "       'Money i have won wining number 946 wot do i do next'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise: show the message text for the false negatives\n",
    "X_test[y_test > preds]\n",
    "# or\n",
    "X_test[(y_test == 1) & (preds == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98295964  0.98026906  0.97845601  0.98114901  0.97935368]\n"
     ]
    }
   ],
   "source": [
    "## USING ALL DATA AND CROSS-VALIDATION and run NB again\n",
    "\n",
    "# make word count vector for messages\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(df.msg)\n",
    "\n",
    "# make DTM which has word counts per message\n",
    "dtm = vect.transform(df.msg)\n",
    "\n",
    "# fit using DTM and labels\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "nb = MultinomialNB()\n",
    "nb.fit(dtm, df.label)\n",
    "\n",
    "# get scores from cross validation\n",
    "scores = cross_val_score(nb, dtm, df.label, cv=5)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4825\n",
      "747\n"
     ]
    }
   ],
   "source": [
    "## EXERCISE: CALCULATE THE 'SPAMMINESS' OF EACH TOKEN\n",
    "\n",
    "# create separate DataFrames for ham and spam ( df_ham and df_spam)\n",
    "df_ham = df[df.label==0]\n",
    "print len(df_ham)\n",
    "\n",
    "df_spam = df[df.label==1]\n",
    "print len(df_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724\n"
     ]
    }
   ],
   "source": [
    "# learn the vocabulary of ALL messages and save it\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(df.msg)\n",
    "vocab = pd.DataFrame(vect.get_feature_names())\n",
    "print len(vocab)\n",
    "vocab.to_csv('vocab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4825\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "ham_dtm = vect.transform(df[df.label==0].msg)\n",
    "ham_arr = ham_dtm.toarray()\n",
    "print len(ham_arr)\n",
    "print ham_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n"
     ]
    }
   ],
   "source": [
    "# create document-term matrix of spam, then convert to a regular array\n",
    "spam_dtm = vect.transform(df[df.label==1].msg)\n",
    "spam_arr = spam_dtm.toarray()\n",
    "print len(spam_arr)\n",
    "#print spam_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 29  0 ...,  0  1  0]\n",
      "8724\n",
      "[0 0 1 ..., 1 0 1]\n",
      "8724\n"
     ]
    }
   ],
   "source": [
    "# count how many times EACH token appears across ALL messages in spam_arr\n",
    "spam_word_counts = np.sum(spam_arr, axis = 0)\n",
    "len(spam_word_counts)\n",
    "print spam_word_counts\n",
    "print len(spam_word_counts)\n",
    "\n",
    "ham_word_counts = np.sum(ham_arr, axis = 0)\n",
    "len(ham_word_counts)\n",
    "print ham_word_counts\n",
    "print len(ham_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8724\n",
      "8724\n",
      "8724\n",
      "      ham_count  spam_count          word\n",
      "0             0          10            00\n",
      "1             0          29           000\n",
      "2             1           0        000pes\n",
      "3             0           2  008704050406\n",
      "4             0           1          0089\n",
      "5             0           1          0121\n",
      "6             0           1   01223585236\n",
      "7             0           2   01223585334\n",
      "8             1           0    0125698789\n",
      "9             0           8            02\n",
      "10            0           3          0207\n",
      "11            0           1   02072069400\n",
      "12            0           2   02073162414\n",
      "13            0           1   02085076972\n",
      "14            0           2           021\n",
      "15            0          13            03\n",
      "16            0          12            04\n",
      "17            0           1          0430\n",
      "18            0           5            05\n",
      "19            0           2        050703\n",
      "20            0           2          0578\n",
      "21            0           8            06\n",
      "22            0           2            07\n",
      "23            0           1   07008009200\n",
      "24            0           1   07046744435\n",
      "25            0           1   07090201529\n",
      "26            0           1   07090298926\n",
      "27            0           1   07099833605\n",
      "28            0           2   07123456789\n",
      "29            0           1       0721072\n",
      "...         ...         ...           ...\n",
      "8694          1           0       youuuuu\n",
      "8695          1           0      youwanna\n",
      "8696          1           0       yoville\n",
      "8697          1           0       yowifes\n",
      "8698          1           0       yoyyooo\n",
      "8699          3          11            yr\n",
      "8700          5           3           yrs\n",
      "8701          1           0       ystrday\n",
      "8702          1           0        ything\n",
      "8703          1           0        yummmm\n",
      "8704          3           0         yummy\n",
      "8705          5           0           yun\n",
      "8706          2           0         yunny\n",
      "8707          4           0           yuo\n",
      "8708          1           0          yuou\n",
      "8709         43           0           yup\n",
      "8710          1           0          yupz\n",
      "8711          1           0           zac\n",
      "8712          1           0         zaher\n",
      "8713          1           0       zealand\n",
      "8714          0           1         zebra\n",
      "8715          0           6           zed\n",
      "8716          1           0         zeros\n",
      "8717          1           0         zhong\n",
      "8718          2           0        zindgi\n",
      "8719          1           1           zoe\n",
      "8720          1           0     zogtorius\n",
      "8721          1           0          zoom\n",
      "8722          0           1          zouk\n",
      "8723          1           0         zyada\n",
      "\n",
      "[8724 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "print len(vect.get_feature_names())\n",
    "print len(ham_word_counts.tolist())\n",
    "print len(spam_word_counts.tolist())\n",
    "d = {\n",
    "    'word': vect.get_feature_names(), \n",
    "    'ham_count': ham_word_counts.tolist(), \n",
    "    'spam_count': spam_word_counts.tolist()\n",
    "}\n",
    "\n",
    "counts_df = pd.DataFrame(data=d)\n",
    "print counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add one to ham counts and spam counts so that ratio calculations (below) make more sensse\n",
    "counts_df['spam_count'] = counts_df.spam_count + 1\n",
    "counts_df['ham_count'] = counts_df.ham_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ham_count  spam_count        word       ratio\n",
      "2070          1         114       claim  114.000000\n",
      "6121          1          94       prize   94.000000\n",
      "352           1          72        150p   72.000000\n",
      "7847          1          61        tone   61.000000\n",
      "368           1          52          18   52.000000\n",
      "3695          1          51  guaranteed   51.000000\n",
      "2377          1          45          cs   45.000000\n",
      "615           1          45         500   45.000000\n",
      "299           1          42        1000   42.000000\n",
      "1334          1          39     awarded   39.000000\n",
      "8028          2          75          uk   37.500000\n",
      "356           1          35      150ppm   35.000000\n",
      "6534          1          33    ringtone   33.000000\n",
      "8609          3          99         www   33.000000\n",
      "1             1          30         000   30.000000\n",
      "2969          1          27       entry   27.000000\n",
      "7848          1          27       tones   27.000000\n",
      "363           2          54          16   27.000000\n",
      "2153          1          27  collection   27.000000\n",
      "616           1          26        5000   26.000000\n",
      "5124          1          26         mob   26.000000\n",
      "8387          1          25      weekly   25.000000\n",
      "309           1          25         10p   25.000000\n",
      "8165          1          25       valid   25.000000\n",
      "5304          1          23    national   23.000000\n",
      "730           1          23         800   23.000000\n",
      "4002          1          22        http   22.000000\n",
      "6628          1          22         sae   22.000000\n",
      "733           1          22        8007   22.000000\n",
      "8260          1          22    vouchers   22.000000\n",
      "...         ...         ...         ...         ...\n",
      "3933        166           3        home    0.018072\n",
      "2821         56           1         dun    0.017857\n",
      "5540        115           2          oh    0.017391\n",
      "5224        116           2        much    0.017241\n",
      "5261        755          13          my    0.017219\n",
      "1065         59           1      always    0.016949\n",
      "3602         59           1       gonna    0.016949\n",
      "7010         59           1       sleep    0.016949\n",
      "5378         63           1        nice    0.015873\n",
      "3177         63           1        feel    0.015873\n",
      "8406         63           1        went    0.015873\n",
      "3697         68           1         gud    0.014706\n",
      "7108         70           1   something    0.014286\n",
      "7472         72           1        sure    0.013889\n",
      "4730         75           1         lol    0.013333\n",
      "2292         77           1         cos    0.012987\n",
      "2166        231           3        come    0.012987\n",
      "1143         77           1    anything    0.012987\n",
      "5174         80           1     morning    0.012500\n",
      "2720         89           1       doing    0.011236\n",
      "1085         89           1         amp    0.011236\n",
      "1248         90           1         ask    0.011111\n",
      "6635         90           1        said    0.011111\n",
      "4558        136           1       later    0.007353\n",
      "2434        151           1          da    0.006623\n",
      "4753        163           1         lor    0.006135\n",
      "6851        168           1         she    0.005952\n",
      "3812        231           1          he    0.004329\n",
      "4799        317           1          lt    0.003155\n",
      "3691        319           1          gt    0.003135\n",
      "\n",
      "[8724 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# calculate ratio of spam-to-ham for each token\n",
    "counts_df['ratio'] = counts_df['spam_count'] / counts_df['ham_count']\n",
    "print counts_df.sort_index(by='ratio', ascending=False)\n",
    "\n",
    "#print counts_df.ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# advanced: implement your own naive bayes classifier\n",
    "# P = (A * B ) / C\n",
    "# A = given that mesg is spam, probability of that word showing up\n",
    "# B = probability of spam in general\n",
    "# C = probability of that word\n",
    "def nbc(df, dtm):\n",
    "    df[df.label==1]\n",
    "\n",
    "# calculate probability for each class and compare; highest probability = class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
