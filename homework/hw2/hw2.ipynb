{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python imports\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn import neighbors, datasets, feature_selection\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "import collections\n",
    "import operator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "iris_df['Target'] = iris.target"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Implement KNN classification, using the sklearn package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "X_train  [[ 5.4  3.7  1.5  0.2]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 5.1  3.5  1.4  0.2]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 5.9  3.   5.1  1.8]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 6.6  3.   4.4  1.4]]\n",
      "X_test  [[ 5.   3.5  1.3  0.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 4.8  3.   1.4  0.1]]\n",
      "y_train  [0 0 0 2 0 2 1 1 1 0 2 1 1 2 0 2 0 2 2 2 2 1 1 1 1 2 0 2 2 0 1 0 2 2 0 1 1\n",
      " 0 0 1 1 1 1 2 1 2 0 0 1 1 1 0 2 1 0 2 2 1 2 2 0 0 2 1 1 2 0 1 1 0 1 1 2 2\n",
      " 1 0 2 0 2 0 0 1 2 2 1 2 2 0 1 1 0 2 2 2 1 2 2 2 0 0 1 0 2 2 1]\n",
      "y_test  [0 2 0 1 2 2 2 0 2 0 1 0 0 0 1 2 2 1 0 1 0 1 2 1 0 2 1 1 0 0 0 1 2 0 2 0 1\n",
      " 1 0 1 1 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10b911a90>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2QBwsDczGwD/H176Y0AZFsBgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1030a4b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# splitting data and target classifications into train and test sets and run KNN classification\n",
    "def knn(data, target, n_neighbors):\n",
    "\n",
    "    # split the data into train and test datasets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=12)\n",
    "\n",
    "    print type(x_train)\n",
    "    print type(x_test)\n",
    "    print type(y_train)\n",
    "    print type(y_test)\n",
    "    \n",
    "    print \"X_train \", x_train\n",
    "    print \"X_test \", x_test\n",
    "    print \"y_train \", y_train\n",
    "    print \"y_test \", y_test\n",
    "    \n",
    "    # Loop through each neighbors value and append the scores\n",
    "    scores = []\n",
    "    for n in n_neighbors:\n",
    "        clf = neighbors.KNeighborsClassifier(n)\n",
    "        clf.fit(x_train, y_train)\n",
    "        scores.append(clf.score(x_test, y_test))\n",
    "        \n",
    "    return scores\n",
    "\n",
    "# use function on iris data\n",
    "n_neighbors = n_neighbors = range(1, 51, 2)\n",
    "scores = knn(iris.data, iris.target, n_neighbors)\n",
    "\n",
    "# plot result\n",
    "plt.plot(n_neighbors, scores, linewidth=3.0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2. Use the sklearn package to implement cross-validation for your classifier. Use 5 folds for your cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96666667  0.96666667  0.93333333  0.93333333  1.        ]\n",
      "0.96\n",
      "[ 0.96666667  0.96666667  0.93333333  0.96666667  1.        ]\n",
      "0.966666666667\n",
      "[ 0.96666667  1.          0.93333333  0.96666667  1.        ]\n",
      "0.973333333333\n",
      "[ 0.96666667  1.          0.96666667  0.96666667  1.        ]\n",
      "0.98\n",
      "[ 0.96666667  1.          0.96666667  0.93333333  1.        ]\n",
      "0.973333333333\n",
      "[ 0.93333333  1.          1.          0.96666667  1.        ]\n",
      "0.98\n",
      "[ 0.93333333  1.          0.96666667  0.96666667  1.        ]\n",
      "0.973333333333\n",
      "[ 0.93333333  1.          0.93333333  0.96666667  1.        ]\n",
      "0.966666666667\n",
      "[ 0.93333333  1.          0.93333333  0.96666667  1.        ]\n",
      "0.966666666667\n",
      "[ 0.93333333  1.          0.93333333  0.96666667  1.        ]\n",
      "0.966666666667\n",
      "[ 0.93333333  1.          0.93333333  0.96666667  1.        ]\n",
      "0.966666666667\n",
      "[ 0.93333333  1.          0.93333333  0.93333333  1.        ]\n",
      "0.96\n",
      "[ 0.93333333  0.96666667  0.93333333  0.96666667  1.        ]\n",
      "0.96\n",
      "[ 0.9         0.96666667  0.93333333  0.93333333  1.        ]\n",
      "0.946666666667\n",
      "[ 0.9         0.96666667  0.9         0.9         1.        ]\n",
      "0.933333333333\n",
      "[ 0.9         0.96666667  0.9         0.9         1.        ]\n",
      "0.933333333333\n",
      "[ 0.93333333  0.96666667  0.9         0.9         1.        ]\n",
      "0.94\n",
      "[ 0.93333333  0.96666667  0.93333333  0.93333333  1.        ]\n",
      "0.953333333333\n",
      "[ 0.9         0.96666667  0.93333333  0.93333333  1.        ]\n",
      "0.946666666667\n",
      "[ 0.9         0.93333333  0.93333333  0.93333333  1.        ]\n",
      "0.94\n",
      "[ 0.9         0.93333333  0.93333333  0.93333333  1.        ]\n",
      "0.94\n",
      "[ 0.9         0.93333333  0.93333333  0.93333333  1.        ]\n",
      "0.94\n",
      "[ 0.9         0.93333333  0.9         0.96666667  1.        ]\n",
      "0.94\n",
      "[ 0.9         0.93333333  0.86666667  0.96666667  0.96666667]\n",
      "0.926666666667\n",
      "[ 0.9         0.93333333  0.9         0.96666667  1.        ]\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "def xvalidate(data, target, n_neighbor):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbor, weights='uniform')\n",
    "    clf.fit(data, target)\n",
    "    scores = cross_val_score(clf, data, target, cv=5)\n",
    "    return scores\n",
    "\n",
    "def mean(values):\n",
    "    tot = 0\n",
    "    for v in values:\n",
    "        tot += v\n",
    "    return tot / len(values)\n",
    "\n",
    "for x in range(1, 51, 2):\n",
    "    xvalidate_scores = xvalidate(iris.data, iris.target, x)\n",
    "    print xvalidate_scores\n",
    "    print mean(xvalidate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Use your KNN classifier and cross-validation code from (1) and (2) above to determine the optimal value of K (number of nearest neighbors to consult) for this Iris dataset. Hint: This hyperparameter will be a number between 1 and 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print len(iris.data)\n",
    "\n",
    "def find_optimal_k(data):\n",
    "    max_neighbors = int(len(data) / 2)\n",
    "    neighbor_scores = {}\n",
    "    for x in range(1, max_neighbors, 1):\n",
    "        xvalidate_scores = xvalidate(iris.data, iris.target, x)        \n",
    "        avg = mean(xvalidate_scores)\n",
    "        neighbor_scores[x] = avg\n",
    "    max_value = max(neighbor_scores.values())\n",
    "    max_index = neighbor_scores.values().index(max_value)\n",
    "    return max_index\n",
    "\n",
    "k = find_optimal_k(iris.data)\n",
    "print k\n",
    "#print max_index, max_value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range of K that you consider interesting. Explain in words what you are seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neighbor_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c86ec372b265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'neighbor_scores' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(neighbor_scores.keys(), neighbor_scores.values())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Now, write your own implementation of cross-validation in Python without using the cross-validation methods from sklearn. Cross validation is a very important concept. Implementing it yourself in Python is the best way to learn and understand it. Compare the results of your cross-validation code with your results using the cross-validation in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def my_xvalidate(data, target, folds):\n",
    "    data_indices = range(0, len(data), 1)\n",
    "    random.shuffle(data_indices)    \n",
    "    n_items = int((len(data) / folds))\n",
    "    begin_index = 0\n",
    "    end_index = n_items - 1\n",
    "    n_neighbors = [11]\n",
    "    scores = []\n",
    "    for n_fold in range(folds):\n",
    "        fold_data = data[begin_index:end_index, :]\n",
    "        fold_labels = target[begin_index:end_index]\n",
    "        fold_score = knn(fold_data, fold_labels, n_neighbors)\n",
    "        scores.append(fold_score[0])\n",
    "        begin_index += n_items\n",
    "        end_index += n_items    \n",
    "    return scores\n",
    "    \n",
    "scores = my_xvalidate(iris.data, iris.target, 5)\n",
    "print scores\n",
    "print mean(scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. EXTRA CREDIT 1: Using the value of K obtained in (3) above, vary the number of folds used for cross-validation across an interesting range, e.g. [ 2, 3, 5, 6, 10, 15]. How does classifier accuracy vary with the number of folds used? Do you think there exists an optimal number of folds to use for this particular problem? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_neighbors = [2, 3, 5, 6, 10, 15]\n",
    "xvalidate_scores = []\n",
    "for n_neighbor in n_neighbors:\n",
    "    scores = xvalidate(iris.data, iris.target, n_neighbor)\n",
    "    #print scores\n",
    "    #print mean(scores)\n",
    "    xvalidate_scores.append(mean(scores))\n",
    "    \n",
    "plt.plot(n_neighbors, xvalidate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. EXTRA CREDIT 2: Write your own implementation of KNN classification in Python, without using the methods from sklearn. Compare your results with the results you obtained using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.88\n"
     ]
    }
   ],
   "source": [
    "# TODO TODO TODO\n",
    "\n",
    "import math\n",
    "\n",
    "# compute distance between two N-dimensional points\n",
    "def dist(data1, data2):\n",
    "    tot = 0\n",
    "    for i in range(len(data1)):\n",
    "        d = data1[i] - data2[i]\n",
    "        tot += math.pow(d, 2)\n",
    "    return math.sqrt(tot)\n",
    "\n",
    "# get the label of a point by looking at the classification of its K closest neighbors\n",
    "def get_label(data, labels, point, k):\n",
    "        \n",
    "    # get the distances between this point and every other\n",
    "    distances = {}\n",
    "    for i in range(len(data)):        \n",
    "        # FIXME: probably want to ignore this point here to avoid hacks later\n",
    "        distances[i] = dist(data[i], point)\n",
    "        \n",
    "    # sort the distances\n",
    "    sorted_distances = sorted(distances.items(), key=operator.itemgetter(1))\n",
    "         \n",
    "    # get the data indices of the closest K points, ignoring distance 0 which is this point! \n",
    "    indices = []\n",
    "    for j in range(k+1):\n",
    "        if (sorted_distances[j][1] != 0.):\n",
    "            indices.append(sorted_distances[j][0])\n",
    "            \n",
    "    # get the labels of these points\n",
    "    neighbor_labels = []\n",
    "    for i in indices:\n",
    "        neighbor_labels.append(labels[i])\n",
    "                \n",
    "    # count the label values\n",
    "    label_counts = collections.Counter(neighbor_labels)\n",
    "    sorted_counts = sorted(label_counts.items(), key=operator.itemgetter(1))\n",
    "        \n",
    "    # return the label with the most counts\n",
    "    return sorted_counts[0][0]\n",
    "        \n",
    "def my_knn(values, target, k):\n",
    "    labels = []\n",
    "    for i in range(len(values)):\n",
    "        value = values[i]\n",
    "        label = get_label(values, target, value, k)\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def compute_score(test, train):\n",
    "    nright = 0\n",
    "    for i in range(len(test)):\n",
    "        if (test[i] == train[i]):\n",
    "            nright += 1\n",
    "    return nright / len(test)\n",
    "\n",
    "# get the labels from running my KNN method (example of just running on all data and labels)\n",
    "labels = my_knn(iris.data, iris.target, 5)\n",
    "\n",
    "#print \"labels\", labels\n",
    "\n",
    "score = compute_score(labels, iris.target)\n",
    "print \"score\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
