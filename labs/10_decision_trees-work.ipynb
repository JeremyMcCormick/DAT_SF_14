{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Decision Trees\n",
    "\n",
    "*Adapted from Chapter 8 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)*\n",
    "\n",
    "||continuous|categorical|\n",
    "|---|---|---|\n",
    "|**supervised**|**regression**|**classification**|\n",
    "|**unsupervised**|dimension reduction|clustering|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression trees\n",
    "\n",
    "Let's look at a simple example to motivate our learning.\n",
    "\n",
    "Our goal is to **predict a baseball player's Salary** based on **Years** (number of years playing in the major leagues) and **Hits** (number of hits he made in the previous year). Here is the training data, represented visually (low salary is blue/green, high salary is red/yellow):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_salary_color.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How might you \"stratify\" or \"segment\" the feature space into regions, based on salary?** Intuitively, you want to **maximize** the similarity (or \"homogeneity\") within a given region, and **minimize** the similarity between different regions.\n",
    "\n",
    "Below is a regression tree that has been fit to the data by a computer. (We will talk later about how the fitting algorithm actually works.) Note that  Salary is measured in thousands and has been log-transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_salary_tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we make Salary predictions (for out-of-sample data) using a decision tree?**\n",
    "\n",
    "- Start at the top, and examine the first \"splitting rule\" (Years < 4.5).\n",
    "- If the rule is True for a given player, follow the left branch. If the rule is False, follow the right branch.\n",
    "- Continue until reaching the bottom. The predicted Salary is the number in that particular \"bucket\".\n",
    "- *Side note:* Years and Hits are both integers, but the convention is to label these rules using the midpoint between adjacent values.\n",
    "\n",
    "Examples predictions:\n",
    "\n",
    "- Years=3, then predict 5.11 ($\\$1000 \\times e^{5.11} \\approx \\$166000$)\n",
    "- Years=5 and Hits=100, then predict 6.00 ($\\$1000 \\times e^{6.00} \\approx \\$403000$)\n",
    "- Years=8 and Hits=120, then predict 6.74 ($\\$1000 \\times e^{6.74} \\approx \\$846000$)\n",
    "\n",
    "**How did we come up with the numbers at the bottom of the tree?** Each number is just the **mean Salary in the training data** of players who fit that criteria. Here's the same diagram as before, split into the three regions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_salary_regions.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This diagram is essentially a combination of the two previous diagrams (except that the observations are no longer color-coded). In $R_1$, the mean log Salary was 5.11. In $R_2$, the mean log Salary was 6.00. In $R_3$, the mean log Salary was 6.74. Thus, those values are used to predict out-of-sample data.\n",
    "\n",
    "Let's introduce some terminology:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_salary_tree_annotated.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How might you interpret the \"meaning\" of this tree?**\n",
    "\n",
    "- Years is the most important factor determining Salary, with a lower number of Years corresponding to a lower Salary.\n",
    "- For a player with a lower number of Years, Hits is not an important factor determining Salary.\n",
    "- For a player with a higher number of Years, Hits is an important factor determining Salary, with a greater number of Hits corresponding to a higher Salary.\n",
    "\n",
    "What we have seen so far hints at the advantages and disadvantages of decision trees:\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Highly interpretable\n",
    "- Can be displayed graphically\n",
    "- Prediction is fast\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Predictive accuracy is not as high as some supervised learning methods\n",
    "- Can easily overfit the training data (high variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a regression tree by hand\n",
    "\n",
    "How do you build a decision tree? You're going to find out by building one!\n",
    "\n",
    "Your training data is a tiny dataset of [used vehicle sale prices](https://raw.githubusercontent.com/justmarkham/DAT4/master/data/used_vehicles.csv). Your goal is to predict Price for out-of-sample data. Here are your instructions:\n",
    "\n",
    "- Read the data into Pandas.\n",
    "- Explore the data by sorting, plotting, or split-apply-combine (aka `group_by`).\n",
    "- Decide which feature is the most important predictor, and use that to make your first split. (Only binary splits are allowed!)\n",
    "- After making your first split, you should actually split your data in Pandas into two parts, and then explore each part to figure out what other splits to make.\n",
    "- Stop making splits once you are convinced that it strikes a good balance between underfitting and overfitting. (As always, your goal is to build a model that generalizes well!)\n",
    "- You are allowed to split on the same variable multiple times!\n",
    "- Draw your tree, making sure to label your leaves with the mean Price for the observations in that \"bucket\".\n",
    "- When you're finished, review your tree to make sure nothing is backwards. (Remember: follow the left branch if the rule is true, and follow the right branch if the rule is false.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does a computer build a regression tree?\n",
    "\n",
    "The ideal approach would be for the computer to consider every possible partition of the feature space. However, this is computationally infeasible, so instead an approach is used called **recursive binary splitting:**\n",
    "\n",
    "- Begin at the top of the tree.\n",
    "- For every single predictor, examine every possible cutpoint, and choose the predictor and cutpoint such that the resulting tree has the **lowest possible mean squared error (MSE)**. Make that split.\n",
    "- Repeat the examination for the two resulting regions, and again make a single split (in one of the regions) to minimize the MSE.\n",
    "- Keep repeating this process until a stopping criteria is met.\n",
    "\n",
    "**How does it know when to stop?**\n",
    "\n",
    "1. We could define a stopping criterion, such as a **maximum depth** of the tree or the **minimum number of samples in the leaf**.\n",
    "2. We could grow the tree deep, and then \"prune\" it back using a method such as \"cost complexity pruning\" (aka \"weakest link pruning\").\n",
    "\n",
    "Method 2 involves setting a tuning parameter that penalizes the tree for having too many leaves. As the parameter is increased, branches automatically get pruned from the tree, resulting in smaller and smaller trees. The tuning parameter can be selected through cross-validation.\n",
    "\n",
    "Note: **Method 2 is not currently supported by scikit-learn**, and so we will use Method 1 instead.\n",
    "\n",
    "Here's an example of an **unpruned tree**, and a comparison of the training, test, and cross-validation errors for trees with different numbers of leaves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_salary_unpruned.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the **training error** continues to go down as the tree size increases, but the lowest **cross-validation error** occurs for a tree with 3 leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a regression tree in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td> 22000</td>\n",
       "      <td> 2012</td>\n",
       "      <td>  13000</td>\n",
       "      <td> 2</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td> 14000</td>\n",
       "      <td> 2010</td>\n",
       "      <td>  30000</td>\n",
       "      <td> 2</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> 13000</td>\n",
       "      <td> 2010</td>\n",
       "      <td>  73500</td>\n",
       "      <td> 4</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>  9500</td>\n",
       "      <td> 2009</td>\n",
       "      <td>  78000</td>\n",
       "      <td> 4</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>  9000</td>\n",
       "      <td> 2007</td>\n",
       "      <td>  47000</td>\n",
       "      <td> 4</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>  4000</td>\n",
       "      <td> 2006</td>\n",
       "      <td> 124000</td>\n",
       "      <td> 2</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td>  3000</td>\n",
       "      <td> 2004</td>\n",
       "      <td> 177000</td>\n",
       "      <td> 4</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>  2000</td>\n",
       "      <td> 2004</td>\n",
       "      <td> 209000</td>\n",
       "      <td> 4</td>\n",
       "      <td> truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>  3000</td>\n",
       "      <td> 2003</td>\n",
       "      <td> 138000</td>\n",
       "      <td> 2</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td>  1900</td>\n",
       "      <td> 2003</td>\n",
       "      <td> 160000</td>\n",
       "      <td> 4</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>  2500</td>\n",
       "      <td> 2003</td>\n",
       "      <td> 190000</td>\n",
       "      <td> 2</td>\n",
       "      <td> truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>  5000</td>\n",
       "      <td> 2001</td>\n",
       "      <td>  62000</td>\n",
       "      <td> 4</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>  1800</td>\n",
       "      <td> 1999</td>\n",
       "      <td> 163000</td>\n",
       "      <td> 2</td>\n",
       "      <td> truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>  1300</td>\n",
       "      <td> 1997</td>\n",
       "      <td> 138000</td>\n",
       "      <td> 4</td>\n",
       "      <td>   car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors   type\n",
       "0   22000  2012   13000      2    car\n",
       "1   14000  2010   30000      2    car\n",
       "2   13000  2010   73500      4    car\n",
       "3    9500  2009   78000      4    car\n",
       "4    9000  2007   47000      4    car\n",
       "5    4000  2006  124000      2    car\n",
       "6    3000  2004  177000      4    car\n",
       "7    2000  2004  209000      4  truck\n",
       "8    3000  2003  138000      2    car\n",
       "9    1900  2003  160000      4    car\n",
       "10   2500  2003  190000      2  truck\n",
       "11   5000  2001   62000      4    car\n",
       "12   1800  1999  163000      2  truck\n",
       "13   1300  1997  138000      4    car"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read in vehicle data\n",
    "vehicles = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT4/master/data/used_vehicles.csv')\n",
    "\n",
    "# print out data\n",
    "vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13500.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles[vehicles.year >= 2007].price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles[vehicles.miles < 35000].price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10500.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles[(vehicles.year >= 2007) & (vehicles.miles > 35000)].price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert car to 0 and truck to 1\n",
    "vehicles['type'] = vehicles.type.map({'car':0, 'truck':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.index.Index'>\n"
     ]
    }
   ],
   "source": [
    "# select feature columns (every column except for the 0th column)\n",
    "feature_cols = vehicles.columns[1:]\n",
    "\n",
    "print type(feature_cols)\n",
    "\n",
    "#print vehicles.columns\n",
    "#print feature_cols\n",
    "\n",
    "# define X (features) and y (response)\n",
    "X = vehicles[feature_cols]\n",
    "y = vehicles.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2003 190000      2      1]\n",
      " [  2007  47000      4      0]\n",
      " [  2010  30000      2      0]\n",
      " [  1999 163000      2      1]\n",
      " [  2012  13000      2      0]\n",
      " [  1997 138000      4      0]\n",
      " [  2003 160000      4      0]\n",
      " [  2003 138000      2      0]\n",
      " [  2001  62000      4      0]\n",
      " [  2006 124000      2      0]]\n",
      "[ 2500  9000 14000  1800 22000  1300  1900  3000  5000  4000]\n",
      "[[  2009  78000      4      0]\n",
      " [  2004 209000      4      1]\n",
      " [  2004 177000      4      0]\n",
      " [  2010  73500      4      0]]\n",
      "[ 9500  2000  3000 13000]\n"
     ]
    }
   ],
   "source": [
    "# print out each of the arrays\n",
    "print X_train\n",
    "print y_train\n",
    "print X_test\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(compute_importances=None, criterion='mse',\n",
       "           max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "           min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           random_state=1, splitter='best')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import class, instantiate estimator, fit with training set\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treereg = DecisionTreeRegressor(random_state=1)\n",
    "treereg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5000.  1900.  1900.  5000.]\n",
      "[ 9500  2000  3000 13000]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "preds = treereg.predict(X_test)\n",
    "\n",
    "# print predictions and actual values\n",
    "print preds\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to discuss Root Mean Squared Error [RMSE](https://www.kaggle.com/wiki/RootMeanSquaredError)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4622.4993239588475"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print RMSE\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use cross-validation to find best max_depth\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4804.3767888427128"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try max_depth=2\n",
    "treereg = DecisionTreeRegressor(max_depth=2, random_state=1)\n",
    "scores = cross_val_score(treereg, X, y, cv=3, scoring='mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.12050000e+08,  -5.75850000e+06,  -2.03940000e+06])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that we did a -scores in the previous statement. This is because scikit reports mean square error as negative. Some debate/discussions on why the score is negative:\n",
    " https://github.com/scikit-learn/scikit-learn/issues/2439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4592.1554255755254"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try max_depth=3\n",
    "treereg = DecisionTreeRegressor(max_depth=3, random_state=1)\n",
    "scores = cross_val_score(treereg, X, y, cv=3, scoring='mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4704.0052694797387"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try max_depth=4\n",
    "treereg = DecisionTreeRegressor(max_depth=4, random_state=1)\n",
    "scores = cross_val_score(treereg, X, y, cv=3, scoring='mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(compute_importances=None, criterion='mse', max_depth=3,\n",
       "           max_features=None, max_leaf_nodes=None, min_density=None,\n",
       "           min_samples_leaf=1, min_samples_split=2, random_state=1,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_depth=3 was best, so fit a tree using that parameter with ALL DATA\n",
    "treereg = DecisionTreeRegressor(max_depth=3, random_state=1)\n",
    "treereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  year</td>\n",
       "      <td> 0.798744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> miles</td>\n",
       "      <td> 0.201256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> doors</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>  type</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "0    year    0.798744\n",
       "1   miles    0.201256\n",
       "2   doors    0.000000\n",
       "3    type    0.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the \"Gini importance\" of each feature: the (normalized) total reduction of MSE brought by that feature\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':treereg.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Graphviz (optional):\n",
    "* Mac:\n",
    "    * option 1: [Download and install PKG file](http://www.graphviz.org/Download_macos.php)\n",
    "    * option 2: run the code block below\n",
    "* Windows:\n",
    "     [Download and install MSI file](http://www.graphviz.org/Download_windows.php)\n",
    "     * Add it to your Path: Go to Control Panel, System, Advanced System Settings, Environment Variables. Under system \n",
    "       variables,edit \"Path\" to include the path to the \"bin\" folder, such as: C:\\Program Files (x86)\\Graphviz2.38\\bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears Homebrew is already installed. If your intent is to reinstall you\n",
      "should do the following before running this installer again:\n",
      "    rm -rf /usr/local/Cellar /usr/local/.git && brew cleanup\n",
      "\u001b[4;31mWarning\u001b[0m: libtool-2.4.6 already installed\n",
      "\u001b[4;31mWarning\u001b[0m: graphviz-2.38.0 already installed\n"
     ]
    }
   ],
   "source": [
    "### for mac os x only\n",
    "!ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n",
    "!brew install libtool\n",
    "!brew install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a Graphviz file\n",
    "from sklearn.tree import export_graphviz\n",
    "with open(\"Images/15_vehicles.dot\", 'wb') as f:\n",
    "    f = export_graphviz(treereg, out_file=f, feature_names=feature_cols)\n",
    "\n",
    "# at the command line, run this to convert to PNG:\n",
    "# dot -Tpng 15_vehicles.dot -o 15_vehicles.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_vehicles.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting a tree diagram\n",
    "\n",
    "How do we read this decision tree?\n",
    "\n",
    "**Internal nodes:**\n",
    "\n",
    "- \"samples\" is the number of observations in that node before splitting\n",
    "- \"mse\" is the mean squared error calculated by comparing the actual response values in that node against the mean response value in that node\n",
    "- first line is the condition used to split that node (go left if true, go right if false)\n",
    "\n",
    "**Leaves:**\n",
    "\n",
    "- \"samples\" is the number of observations in that node\n",
    "- \"value\" is the mean response value in that node\n",
    "- \"mse\" is the mean squared error calculated by comparing the actual response values in that node against \"value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting for out-of-sample data\n",
    "\n",
    "How accurate is scikit-learn's regression tree at predicting the out-of-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  3000</td>\n",
       "      <td> 2003</td>\n",
       "      <td> 130000</td>\n",
       "      <td> 4</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>  6000</td>\n",
       "      <td> 2005</td>\n",
       "      <td>  82500</td>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 12000</td>\n",
       "      <td> 2010</td>\n",
       "      <td>  60000</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  year   miles  doors  type\n",
       "0   3000  2003  130000      4     1\n",
       "1   6000  2005   82500      4     0\n",
       "2  12000  2010   60000      2     0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in out-of-sample data\n",
    "oos = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT4/master/data/used_vehicles_oos.csv')\n",
    "\n",
    "# convert car to 0 and truck to 1\n",
    "oos['type'] = oos.type.map({'car':0, 'truck':1})\n",
    "\n",
    "# print data\n",
    "oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_oos = oos[feature_cols]\n",
    "y_oos = oos.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4000.   5000.  13500.]\n",
      "[ 3000  6000 12000]\n"
     ]
    }
   ],
   "source": [
    "# make predictions on out-of-sample data\n",
    "preds = treereg.predict(X_oos)\n",
    "\n",
    "# print predictions and actual values\n",
    "print preds\n",
    "print y_oos.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190.2380714238084"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print RMSE\n",
    "np.sqrt(metrics.mean_squared_error(y_oos, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification trees\n",
    "\n",
    "Classification trees are very similar to regression trees. Here is a quick comparison:\n",
    "\n",
    "|regression trees|classification trees|\n",
    "|---|---|\n",
    "|predict a continuous response|predict a categorical response|\n",
    "|predict using mean response of each leaf|predict using most commonly occuring class of each leaf|\n",
    "|splits are chosen to minimize MSE|splits are chosen to minimize a different criterion (discussed below)|\n",
    "\n",
    "Note that classification trees easily handle **more than two response classes**! (How have other classification models we've seen handled this scenario?)\n",
    "\n",
    "Here's an **example of a classification tree**, which predicts whether or not a patient who presented with chest pain has heart disease:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_heart_tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting criteria for classification trees\n",
    "\n",
    "Here are common options for the splitting criteria:\n",
    "\n",
    "- **classification error rate:** fraction of training observations in a region that don't belong to the most common class\n",
    "- **Gini index:** measure of total variance across classes in a region. It basically tries to classify the most frequent class first and then the rest. \n",
    "- **Entropy:** It uses logarithms. The basic idea is generally to have a split of dataset into 50:50 at each level. Try to understand how it is different from Gini. Look at the reference [here](https://www.salford-systems.com/resources/whitepapers/114-do-splitting-rules-really-matter)\n",
    "\n",
    "Which to use?\n",
    "\n",
    "- When growing a tree with 2-3 target labels,  Gini index is probably the best (Default for scikit learn)\n",
    "- When growing a tree with 4-9 target labels,  Entropy has worked bettter in many cases index is probably the best. \n",
    "- When pruning a tree, classification error rate is preferable in order to maximize predictive accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical predictors\n",
    "\n",
    "Some implementations of classification trees will allow you to handle categorical predictors **without creating dummy variables**. When splitting on a categorical predictor, they will try splitting on **every possible combination of categories** to find the best split. In the example above, \"ChestPain:bc\" means that the left-hand branch consists of observations with the second and third ChestPain categories, and the right-hand branch consists of remaining observations.\n",
    "\n",
    "**Unfortunately, scikit-learn's classification tree implementation does not support this approach.** Instead, here's how you can handle categorical predictors:\n",
    "\n",
    "- If a predictor only has **two possible values**, code it as a single binary variable (0 or 1). Since it's treated as a number, splits will naturally occur at 0.5.\n",
    "- If a predictor has **three or more possible values that are ordered**, code it as a single variable (1, 2, 3, etc). Splits will naturally occur at 1.5, 2.5, etc.\n",
    "- If a predictor has **three or more possible values that are unordered**, create dummy variables and drop one level as usual. The decision tree won't know that the dummy variables are related to one another, but that shouldn't matter in terms of predictive accuracy.\n",
    "- If a predictor has **thousands of possible unordered values**, then it may be best to code it as a single variable (1, 2, 3, etc) instead of using dummy variables to minimize the size of the resulting model. ([reference](http://stackoverflow.com/a/18736132/1636598))\n",
    "\n",
    "We'll see examples of these strategies below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a classification tree in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build a classification tree using the [Titanic data](https://www.kaggle.com/c/titanic-gettingStarted/data) provided by Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                           Braund, Mr. Owen Harris</td>\n",
       "      <td>   male</td>\n",
       "      <td> 22</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>        A/5 21171</td>\n",
       "      <td>  7.2500</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td> female</td>\n",
       "      <td> 38</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>         PC 17599</td>\n",
       "      <td> 71.2833</td>\n",
       "      <td>  C85</td>\n",
       "      <td> C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td>                            Heikkinen, Miss. Laina</td>\n",
       "      <td> female</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> STON/O2. 3101282</td>\n",
       "      <td>  7.9250</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td> female</td>\n",
       "      <td> 35</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>           113803</td>\n",
       "      <td> 53.1000</td>\n",
       "      <td> C123</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                          Allen, Mr. William Henry</td>\n",
       "      <td>   male</td>\n",
       "      <td> 35</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>           373450</td>\n",
       "      <td>  8.0500</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                                  Moran, Mr. James</td>\n",
       "      <td>   male</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>           330877</td>\n",
       "      <td>  8.4583</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>                           McCarthy, Mr. Timothy J</td>\n",
       "      <td>   male</td>\n",
       "      <td> 54</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>            17463</td>\n",
       "      <td> 51.8625</td>\n",
       "      <td>  E46</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                    Palsson, Master. Gosta Leonard</td>\n",
       "      <td>   male</td>\n",
       "      <td>  2</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1</td>\n",
       "      <td>           349909</td>\n",
       "      <td> 21.0750</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td> female</td>\n",
       "      <td> 27</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td>           347742</td>\n",
       "      <td> 11.1333</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td>               Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td> female</td>\n",
       "      <td> 14</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>           237736</td>\n",
       "      <td> 30.0708</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass                                               name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "5         0       3                                   Moran, Mr. James   \n",
       "6         0       1                            McCarthy, Mr. Timothy J   \n",
       "7         0       3                     Palsson, Master. Gosta Leonard   \n",
       "8         1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9         1       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "\n",
       "      sex  age  sibsp  parch            ticket     fare cabin embarked  \n",
       "0    male   22      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female   38      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female   26      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female   35      1      0            113803  53.1000  C123        S  \n",
       "4    male   35      0      0            373450   8.0500   NaN        S  \n",
       "5    male  NaN      0      0            330877   8.4583   NaN        Q  \n",
       "6    male   54      0      0             17463  51.8625   E46        S  \n",
       "7    male    2      3      1            349909  21.0750   NaN        S  \n",
       "8  female   27      0      2            347742  11.1333   NaN        S  \n",
       "9  female   14      1      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "titanic = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT4/master/data/titanic.csv')\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived      0\n",
       "pclass        0\n",
       "name          0\n",
       "sex           0\n",
       "age         177\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          0\n",
       "cabin       687\n",
       "embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for missing values\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose our response and a few features, and decide whether we need to adjust them:\n",
    "\n",
    "- **survived:** This is our response, and is already encoded as 0=died and 1=survived.\n",
    "- **pclass:** These are the passenger class categories (1=first class, 2=second class, 3=third class). They are ordered, so we'll leave them as-is.\n",
    "- **sex:** This is a binary category, so we should encode as 0=female and 1=male.\n",
    "- **age:** We need to fill in the missing values.\n",
    "- **embarked:** This is the port they emarked from. There are three unordered categories, so we'll create dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                           Braund, Mr. Owen Harris</td>\n",
       "      <td> 1</td>\n",
       "      <td> 22.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>        A/5 21171</td>\n",
       "      <td>  7.2500</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 38.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>         PC 17599</td>\n",
       "      <td> 71.2833</td>\n",
       "      <td>  C85</td>\n",
       "      <td> C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td>                            Heikkinen, Miss. Laina</td>\n",
       "      <td> 0</td>\n",
       "      <td> 26.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> STON/O2. 3101282</td>\n",
       "      <td>  7.9250</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td> 0</td>\n",
       "      <td> 35.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>           113803</td>\n",
       "      <td> 53.1000</td>\n",
       "      <td> C123</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                          Allen, Mr. William Henry</td>\n",
       "      <td> 1</td>\n",
       "      <td> 35.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>           373450</td>\n",
       "      <td>  8.0500</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                                  Moran, Mr. James</td>\n",
       "      <td> 1</td>\n",
       "      <td> 29.699118</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>           330877</td>\n",
       "      <td>  8.4583</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>                           McCarthy, Mr. Timothy J</td>\n",
       "      <td> 1</td>\n",
       "      <td> 54.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>            17463</td>\n",
       "      <td> 51.8625</td>\n",
       "      <td>  E46</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                    Palsson, Master. Gosta Leonard</td>\n",
       "      <td> 1</td>\n",
       "      <td>  2.000000</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1</td>\n",
       "      <td>           349909</td>\n",
       "      <td> 21.0750</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td> 0</td>\n",
       "      <td> 27.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td>           347742</td>\n",
       "      <td> 11.1333</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td>               Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td> 0</td>\n",
       "      <td> 14.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>           237736</td>\n",
       "      <td> 30.0708</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass                                               name  sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    1   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0   \n",
       "2         1       3                             Heikkinen, Miss. Laina    0   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0   \n",
       "4         0       3                           Allen, Mr. William Henry    1   \n",
       "5         0       3                                   Moran, Mr. James    1   \n",
       "6         0       1                            McCarthy, Mr. Timothy J    1   \n",
       "7         0       3                     Palsson, Master. Gosta Leonard    1   \n",
       "8         1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    0   \n",
       "9         1       2                Nasser, Mrs. Nicholas (Adele Achem)    0   \n",
       "\n",
       "         age  sibsp  parch            ticket     fare cabin embarked  \n",
       "0  22.000000      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  38.000000      1      0          PC 17599  71.2833   C85        C  \n",
       "2  26.000000      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  35.000000      1      0            113803  53.1000  C123        S  \n",
       "4  35.000000      0      0            373450   8.0500   NaN        S  \n",
       "5  29.699118      0      0            330877   8.4583   NaN        Q  \n",
       "6  54.000000      0      0             17463  51.8625   E46        S  \n",
       "7   2.000000      3      1            349909  21.0750   NaN        S  \n",
       "8  27.000000      0      2            347742  11.1333   NaN        S  \n",
       "9  14.000000      1      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode sex feature\n",
    "titanic['sex'] = titanic.sex.map({'female':0, 'male':1})\n",
    "\n",
    "# fill in missing values for age\n",
    "titanic.age.fillna(titanic.age.mean(), inplace=True)\n",
    "\n",
    "# print the updated DataFrame\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   embarked_C  embarked_Q  embarked_S\n",
       "0           0           0           1\n",
       "1           1           0           0\n",
       "2           0           0           1\n",
       "3           0           0           1\n",
       "4           0           0           1\n",
       "5           0           1           0\n",
       "6           0           0           1\n",
       "7           0           0           1\n",
       "8           0           0           1\n",
       "9           1           0           0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create three dummy variables using get_dummies\n",
    "pd.get_dummies(titanic.embarked, prefix='embarked').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                           Braund, Mr. Owen Harris</td>\n",
       "      <td> 1</td>\n",
       "      <td> 22.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>        A/5 21171</td>\n",
       "      <td>  7.2500</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 38.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>         PC 17599</td>\n",
       "      <td> 71.2833</td>\n",
       "      <td>  C85</td>\n",
       "      <td> C</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td>                            Heikkinen, Miss. Laina</td>\n",
       "      <td> 0</td>\n",
       "      <td> 26.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> STON/O2. 3101282</td>\n",
       "      <td>  7.9250</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td> 0</td>\n",
       "      <td> 35.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>           113803</td>\n",
       "      <td> 53.1000</td>\n",
       "      <td> C123</td>\n",
       "      <td> S</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                          Allen, Mr. William Henry</td>\n",
       "      <td> 1</td>\n",
       "      <td> 35.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>           373450</td>\n",
       "      <td>  8.0500</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                                  Moran, Mr. James</td>\n",
       "      <td> 1</td>\n",
       "      <td> 29.699118</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>           330877</td>\n",
       "      <td>  8.4583</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> Q</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>                           McCarthy, Mr. Timothy J</td>\n",
       "      <td> 1</td>\n",
       "      <td> 54.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>            17463</td>\n",
       "      <td> 51.8625</td>\n",
       "      <td>  E46</td>\n",
       "      <td> S</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                    Palsson, Master. Gosta Leonard</td>\n",
       "      <td> 1</td>\n",
       "      <td>  2.000000</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1</td>\n",
       "      <td>           349909</td>\n",
       "      <td> 21.0750</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td> 0</td>\n",
       "      <td> 27.000000</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td>           347742</td>\n",
       "      <td> 11.1333</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> S</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td>               Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td> 0</td>\n",
       "      <td> 14.000000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>           237736</td>\n",
       "      <td> 30.0708</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> C</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass                                               name  sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    1   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0   \n",
       "2         1       3                             Heikkinen, Miss. Laina    0   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0   \n",
       "4         0       3                           Allen, Mr. William Henry    1   \n",
       "5         0       3                                   Moran, Mr. James    1   \n",
       "6         0       1                            McCarthy, Mr. Timothy J    1   \n",
       "7         0       3                     Palsson, Master. Gosta Leonard    1   \n",
       "8         1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    0   \n",
       "9         1       2                Nasser, Mrs. Nicholas (Adele Achem)    0   \n",
       "\n",
       "         age  sibsp  parch            ticket     fare cabin embarked  \\\n",
       "0  22.000000      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  38.000000      1      0          PC 17599  71.2833   C85        C   \n",
       "2  26.000000      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  35.000000      1      0            113803  53.1000  C123        S   \n",
       "4  35.000000      0      0            373450   8.0500   NaN        S   \n",
       "5  29.699118      0      0            330877   8.4583   NaN        Q   \n",
       "6  54.000000      0      0             17463  51.8625   E46        S   \n",
       "7   2.000000      3      1            349909  21.0750   NaN        S   \n",
       "8  27.000000      0      2            347742  11.1333   NaN        S   \n",
       "9  14.000000      1      0            237736  30.0708   NaN        C   \n",
       "\n",
       "   embarked_Q  embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  \n",
       "5           1           0  \n",
       "6           0           1  \n",
       "7           0           1  \n",
       "8           0           1  \n",
       "9           0           0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create three dummy variables, drop the first dummy variable, and store this as a DataFrame\n",
    "embarked_dummies = pd.get_dummies(titanic.embarked, prefix='embarked').ix[:, 1:]\n",
    "\n",
    "# concatenate the two dummy variable columns onto the original DataFrame\n",
    "# note: axis=0 means rows, axis=1 means columns\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1)\n",
    "\n",
    "# print the updated DataFrame\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list of feature columns\n",
    "feature_cols = ['pclass', 'sex', 'age', 'embarked_Q', 'embarked_S']\n",
    "\n",
    "# define X and y\n",
    "X = titanic[feature_cols]\n",
    "y = titanic.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
       "            max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            random_state=1, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a classification tree with max_depth=3 on all data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treeclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a Graphviz file\n",
    "with open(\"Images/15_titanic.dot\", 'wb') as f:\n",
    "    f = export_graphviz(treeclf, out_file=f, feature_names=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_titanic.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the split in the bottom right, which was made only to increase node purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>     pclass</td>\n",
       "      <td> 0.242664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>        sex</td>\n",
       "      <td> 0.655584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>        age</td>\n",
       "      <td> 0.064494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> embarked_Q</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> embarked_S</td>\n",
       "      <td> 0.037258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "0      pclass    0.242664\n",
       "1         sex    0.655584\n",
       "2         age    0.064494\n",
       "3  embarked_Q    0.000000\n",
       "4  embarked_S    0.037258"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the feature importances\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':treeclf.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up decision trees\n",
    "\n",
    "Here are some advantages and disadvantages of decision trees that we haven't yet talked about:\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Can be specified as a series of rules, and are thought to more closely approximate human decision-making than other models\n",
    "- Non-parametric (will do better than linear regression if relationship between predictors and response is highly non-linear)\n",
    "- Decision trees provide a clear indication of which fields are most important for prediction or classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/15_linear_vs_tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disadvantages:**\n",
    "\n",
    "- Decision trees are prone to errors in classification problems with many class and relatively small number of training examples.\n",
    "- Recursive binary splitting makes \"locally optimal\" decisions that may not result in a globally optimal tree\n",
    "- Can create biased trees if the classes are highly imbalanced\n",
    "- Decision tree can be computationally expensive to train. The process of growing a decision tree is computationally expensive. At each node, each candidate splitting field must be sorted before its best split can be found.\n",
    "\n",
    "Note that there is not just one decision tree algorithm; instead, there are many variations. A few common decision tree algorithms that are often referred to by name are C4.5, C5.0, and CART. (More details are available in the [scikit-learn documentation](http://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart).) scikit-learn uses an \"optimized version\" of CART."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Decision Trees](http://scikit-learn.org/stable/modules/tree.html)\n",
    "- Wikipedia: http://en.wikipedia.org/wiki/Decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR TURN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart Disease Dataset\n",
    "ref: [https://archive.ics.uci.edu/ml/datasets/Heart+Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)\n",
    "\n",
    "or under '/labs/data/heart_disease.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "\n",
    "    Dataset has 76 total attributes - 14 attributes are used:\n",
    "    1. #3 (age)\n",
    "    2. #4 (sex)\n",
    "    3. #9 (cp)\n",
    "    4. #10 (trestbps)\n",
    "    5. #12 (chol)\n",
    "    6. #16 (fbs)\n",
    "    7. #19 (restecg)\n",
    "    8. #32 (thalach)\n",
    "    9. #38 (exang)\n",
    "    10. #40 (oldpeak)\n",
    "    11. #41 (slope)\n",
    "    12. #44 (ca)\n",
    "    13. #51 (thal)\n",
    "    14. #58 (num) (the predicted attribute - 0 is healthy and 1,2,3,4 indicate heart disease) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Exercise: Implement Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the dataset into a pandas dataframe:\n",
    "\n",
    "Note: You'll have to manually add column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0  </th>\n",
       "      <td> 63</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 145</td>\n",
       "      <td> 233</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 150</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2.3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 6.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1  </th>\n",
       "      <td> 67</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 160</td>\n",
       "      <td> 286</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 108</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> 2</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2  </th>\n",
       "      <td> 67</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 120</td>\n",
       "      <td> 229</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 129</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.6</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3  </th>\n",
       "      <td> 37</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 130</td>\n",
       "      <td> 250</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 187</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.5</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4  </th>\n",
       "      <td> 41</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 130</td>\n",
       "      <td> 204</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 172</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.4</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5  </th>\n",
       "      <td> 56</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 120</td>\n",
       "      <td> 236</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 178</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.8</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6  </th>\n",
       "      <td> 62</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 140</td>\n",
       "      <td> 268</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 160</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.6</td>\n",
       "      <td> 3</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7  </th>\n",
       "      <td> 57</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 120</td>\n",
       "      <td> 354</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 163</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.6</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8  </th>\n",
       "      <td> 63</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 130</td>\n",
       "      <td> 254</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 147</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.4</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9  </th>\n",
       "      <td> 53</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 140</td>\n",
       "      <td> 203</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 155</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3.1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 </th>\n",
       "      <td> 57</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 140</td>\n",
       "      <td> 192</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 148</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.4</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 6.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11 </th>\n",
       "      <td> 56</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 140</td>\n",
       "      <td> 294</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 153</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.3</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 </th>\n",
       "      <td> 56</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 130</td>\n",
       "      <td> 256</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 142</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.6</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 6.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13 </th>\n",
       "      <td> 44</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 120</td>\n",
       "      <td> 263</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 173</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 </th>\n",
       "      <td> 52</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 172</td>\n",
       "      <td> 199</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 162</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15 </th>\n",
       "      <td> 57</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 150</td>\n",
       "      <td> 168</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 174</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.6</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16 </th>\n",
       "      <td> 48</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 110</td>\n",
       "      <td> 229</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 168</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17 </th>\n",
       "      <td> 54</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 140</td>\n",
       "      <td> 239</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 160</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 </th>\n",
       "      <td> 48</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 130</td>\n",
       "      <td> 275</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 139</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19 </th>\n",
       "      <td> 49</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 130</td>\n",
       "      <td> 266</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 171</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.6</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20 </th>\n",
       "      <td> 64</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 110</td>\n",
       "      <td> 211</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 144</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21 </th>\n",
       "      <td> 58</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 150</td>\n",
       "      <td> 283</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 162</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22 </th>\n",
       "      <td> 58</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 120</td>\n",
       "      <td> 284</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 160</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23 </th>\n",
       "      <td> 58</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 132</td>\n",
       "      <td> 224</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 173</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24 </th>\n",
       "      <td> 60</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 130</td>\n",
       "      <td> 206</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 132</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.4</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 </th>\n",
       "      <td> 50</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 120</td>\n",
       "      <td> 219</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 158</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.6</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26 </th>\n",
       "      <td> 58</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 120</td>\n",
       "      <td> 340</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 172</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27 </th>\n",
       "      <td> 66</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 150</td>\n",
       "      <td> 226</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 114</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2.6</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 </th>\n",
       "      <td> 43</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 150</td>\n",
       "      <td> 247</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 171</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29 </th>\n",
       "      <td> 40</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 110</td>\n",
       "      <td> 167</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 114</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td> 71</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 112</td>\n",
       "      <td> 149</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 125</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.6</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td> 59</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 134</td>\n",
       "      <td> 204</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 162</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.8</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td> 64</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 170</td>\n",
       "      <td> 227</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 155</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.6</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td> 66</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 146</td>\n",
       "      <td> 278</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 152</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td> 39</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 138</td>\n",
       "      <td> 220</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 152</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td> 57</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 154</td>\n",
       "      <td> 232</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 164</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td> 58</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 130</td>\n",
       "      <td> 197</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 131</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.6</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td> 57</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 110</td>\n",
       "      <td> 335</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 143</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td> 47</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 130</td>\n",
       "      <td> 253</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 179</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td> 55</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 128</td>\n",
       "      <td> 205</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 130</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td> 35</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 122</td>\n",
       "      <td> 192</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 174</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td> 61</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 148</td>\n",
       "      <td> 203</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 161</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td> 58</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 114</td>\n",
       "      <td> 318</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 140</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4.4</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 6.0</td>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td> 58</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 170</td>\n",
       "      <td> 225</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 146</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 6.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td> 58</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 125</td>\n",
       "      <td> 220</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 144</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.4</td>\n",
       "      <td> 2</td>\n",
       "      <td>   ?</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td> 56</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 130</td>\n",
       "      <td> 221</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 163</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td> 56</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 120</td>\n",
       "      <td> 240</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 169</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td> 67</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 152</td>\n",
       "      <td> 212</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 150</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td> 55</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 132</td>\n",
       "      <td> 342</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 166</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td> 44</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 120</td>\n",
       "      <td> 169</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 144</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.8</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 6.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td> 63</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 140</td>\n",
       "      <td> 187</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 144</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td> 63</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 124</td>\n",
       "      <td> 197</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 136</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td> 41</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 120</td>\n",
       "      <td> 157</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 182</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td> 59</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 164</td>\n",
       "      <td> 176</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td>  90</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 6.0</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td> 57</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 140</td>\n",
       "      <td> 241</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 123</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td> 45</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 110</td>\n",
       "      <td> 264</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 132</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td> 68</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 144</td>\n",
       "      <td> 193</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 141</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.4</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td> 57</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 130</td>\n",
       "      <td> 131</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 115</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1.2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 7.0</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td> 57</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 130</td>\n",
       "      <td> 236</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 174</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td> 38</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 138</td>\n",
       "      <td> 175</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 173</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 1</td>\n",
       "      <td>   ?</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   1       145   233    1        2      150      0      2.3   \n",
       "1     67    1   4       160   286    0        2      108      1      1.5   \n",
       "2     67    1   4       120   229    0        2      129      1      2.6   \n",
       "3     37    1   3       130   250    0        0      187      0      3.5   \n",
       "4     41    0   2       130   204    0        2      172      0      1.4   \n",
       "5     56    1   2       120   236    0        0      178      0      0.8   \n",
       "6     62    0   4       140   268    0        2      160      0      3.6   \n",
       "7     57    0   4       120   354    0        0      163      1      0.6   \n",
       "8     63    1   4       130   254    0        2      147      0      1.4   \n",
       "9     53    1   4       140   203    1        2      155      1      3.1   \n",
       "10    57    1   4       140   192    0        0      148      0      0.4   \n",
       "11    56    0   2       140   294    0        2      153      0      1.3   \n",
       "12    56    1   3       130   256    1        2      142      1      0.6   \n",
       "13    44    1   2       120   263    0        0      173      0      0.0   \n",
       "14    52    1   3       172   199    1        0      162      0      0.5   \n",
       "15    57    1   3       150   168    0        0      174      0      1.6   \n",
       "16    48    1   2       110   229    0        0      168      0      1.0   \n",
       "17    54    1   4       140   239    0        0      160      0      1.2   \n",
       "18    48    0   3       130   275    0        0      139      0      0.2   \n",
       "19    49    1   2       130   266    0        0      171      0      0.6   \n",
       "20    64    1   1       110   211    0        2      144      1      1.8   \n",
       "21    58    0   1       150   283    1        2      162      0      1.0   \n",
       "22    58    1   2       120   284    0        2      160      0      1.8   \n",
       "23    58    1   3       132   224    0        2      173      0      3.2   \n",
       "24    60    1   4       130   206    0        2      132      1      2.4   \n",
       "25    50    0   3       120   219    0        0      158      0      1.6   \n",
       "26    58    0   3       120   340    0        0      172      0      0.0   \n",
       "27    66    0   1       150   226    0        0      114      0      2.6   \n",
       "28    43    1   4       150   247    0        0      171      0      1.5   \n",
       "29    40    1   4       110   167    0        2      114      1      2.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "273   71    0   4       112   149    0        0      125      0      1.6   \n",
       "274   59    1   1       134   204    0        0      162      0      0.8   \n",
       "275   64    1   1       170   227    0        2      155      0      0.6   \n",
       "276   66    0   3       146   278    0        2      152      0      0.0   \n",
       "277   39    0   3       138   220    0        0      152      0      0.0   \n",
       "278   57    1   2       154   232    0        2      164      0      0.0   \n",
       "279   58    0   4       130   197    0        0      131      0      0.6   \n",
       "280   57    1   4       110   335    0        0      143      1      3.0   \n",
       "281   47    1   3       130   253    0        0      179      0      0.0   \n",
       "282   55    0   4       128   205    0        1      130      1      2.0   \n",
       "283   35    1   2       122   192    0        0      174      0      0.0   \n",
       "284   61    1   4       148   203    0        0      161      0      0.0   \n",
       "285   58    1   4       114   318    0        1      140      0      4.4   \n",
       "286   58    0   4       170   225    1        2      146      1      2.8   \n",
       "287   58    1   2       125   220    0        0      144      0      0.4   \n",
       "288   56    1   2       130   221    0        2      163      0      0.0   \n",
       "289   56    1   2       120   240    0        0      169      0      0.0   \n",
       "290   67    1   3       152   212    0        2      150      0      0.8   \n",
       "291   55    0   2       132   342    0        0      166      0      1.2   \n",
       "292   44    1   4       120   169    0        0      144      1      2.8   \n",
       "293   63    1   4       140   187    0        2      144      1      4.0   \n",
       "294   63    0   4       124   197    0        0      136      1      0.0   \n",
       "295   41    1   2       120   157    0        0      182      0      0.0   \n",
       "296   59    1   4       164   176    1        2       90      0      1.0   \n",
       "297   57    0   4       140   241    0        0      123      1      0.2   \n",
       "298   45    1   1       110   264    0        0      132      0      1.2   \n",
       "299   68    1   4       144   193    1        0      141      0      3.4   \n",
       "300   57    1   4       130   131    0        0      115      1      1.2   \n",
       "301   57    0   2       130   236    0        2      174      0      0.0   \n",
       "302   38    1   3       138   175    0        0      173      0      0.0   \n",
       "\n",
       "     slope   ca thal  num  \n",
       "0        3  0.0  6.0    0  \n",
       "1        2  3.0  3.0    2  \n",
       "2        2  2.0  7.0    1  \n",
       "3        3  0.0  3.0    0  \n",
       "4        1  0.0  3.0    0  \n",
       "5        1  0.0  3.0    0  \n",
       "6        3  2.0  3.0    3  \n",
       "7        1  0.0  3.0    0  \n",
       "8        2  1.0  7.0    2  \n",
       "9        3  0.0  7.0    1  \n",
       "10       2  0.0  6.0    0  \n",
       "11       2  0.0  3.0    0  \n",
       "12       2  1.0  6.0    2  \n",
       "13       1  0.0  7.0    0  \n",
       "14       1  0.0  7.0    0  \n",
       "15       1  0.0  3.0    0  \n",
       "16       3  0.0  7.0    1  \n",
       "17       1  0.0  3.0    0  \n",
       "18       1  0.0  3.0    0  \n",
       "19       1  0.0  3.0    0  \n",
       "20       2  0.0  3.0    0  \n",
       "21       1  0.0  3.0    0  \n",
       "22       2  0.0  3.0    1  \n",
       "23       1  2.0  7.0    3  \n",
       "24       2  2.0  7.0    4  \n",
       "25       2  0.0  3.0    0  \n",
       "26       1  0.0  3.0    0  \n",
       "27       3  0.0  3.0    0  \n",
       "28       1  0.0  3.0    0  \n",
       "29       2  0.0  7.0    3  \n",
       "..     ...  ...  ...  ...  \n",
       "273      2  0.0  3.0    0  \n",
       "274      1  2.0  3.0    1  \n",
       "275      2  0.0  7.0    0  \n",
       "276      2  1.0  3.0    0  \n",
       "277      2  0.0  3.0    0  \n",
       "278      1  1.0  3.0    1  \n",
       "279      2  0.0  3.0    0  \n",
       "280      2  1.0  7.0    2  \n",
       "281      1  0.0  3.0    0  \n",
       "282      2  1.0  7.0    3  \n",
       "283      1  0.0  3.0    0  \n",
       "284      1  1.0  7.0    2  \n",
       "285      3  3.0  6.0    4  \n",
       "286      2  2.0  6.0    2  \n",
       "287      2    ?  7.0    0  \n",
       "288      1  0.0  7.0    0  \n",
       "289      3  0.0  3.0    0  \n",
       "290      2  0.0  7.0    1  \n",
       "291      1  0.0  3.0    0  \n",
       "292      3  0.0  6.0    2  \n",
       "293      1  2.0  7.0    2  \n",
       "294      2  0.0  3.0    1  \n",
       "295      1  0.0  3.0    0  \n",
       "296      2  2.0  6.0    3  \n",
       "297      2  0.0  7.0    1  \n",
       "298      2  0.0  7.0    1  \n",
       "299      2  2.0  7.0    2  \n",
       "300      2  1.0  7.0    3  \n",
       "301      2  1.0  3.0    1  \n",
       "302      1    ?  3.0    0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart = pd.read_csv('data/heart_disease.csv', \n",
    "                    names=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak',\n",
    "                            'slope', 'ca', 'thal', 'num'])\n",
    "\n",
    "# print out data\n",
    "heart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare and validate the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the data and check for missing values - we've used .info() before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null float64\n",
      "sex         303 non-null float64\n",
      "cp          303 non-null float64\n",
      "trestbps    303 non-null float64\n",
      "chol        303 non-null float64\n",
      "fbs         303 non-null float64\n",
      "restecg     303 non-null float64\n",
      "thalach     303 non-null float64\n",
      "exang       303 non-null float64\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null float64\n",
      "ca          303 non-null object\n",
      "thal        303 non-null object\n",
      "num         303 non-null int64\n",
      "dtypes: float64(11), int64(1), object(2)"
     ]
    }
   ],
   "source": [
    "heart.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data to ensure it can be used in a random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "      <td> 303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>  54.438944</td>\n",
       "      <td>   0.679868</td>\n",
       "      <td>   3.158416</td>\n",
       "      <td> 131.689769</td>\n",
       "      <td> 246.693069</td>\n",
       "      <td>   0.148515</td>\n",
       "      <td>   0.990099</td>\n",
       "      <td> 149.607261</td>\n",
       "      <td>   0.326733</td>\n",
       "      <td>   1.039604</td>\n",
       "      <td>   1.600660</td>\n",
       "      <td>   0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>   9.038662</td>\n",
       "      <td>   0.467299</td>\n",
       "      <td>   0.960126</td>\n",
       "      <td>  17.599748</td>\n",
       "      <td>  51.776918</td>\n",
       "      <td>   0.356198</td>\n",
       "      <td>   0.994971</td>\n",
       "      <td>  22.875003</td>\n",
       "      <td>   0.469794</td>\n",
       "      <td>   1.161075</td>\n",
       "      <td>   0.616226</td>\n",
       "      <td>   1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>  29.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>  94.000000</td>\n",
       "      <td> 126.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>  71.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>  48.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td> 120.000000</td>\n",
       "      <td> 211.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td> 133.500000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>  56.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td> 130.000000</td>\n",
       "      <td> 241.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td> 153.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.800000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>  61.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   4.000000</td>\n",
       "      <td> 140.000000</td>\n",
       "      <td> 275.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td> 166.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   1.600000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td>   2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>  77.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   4.000000</td>\n",
       "      <td> 200.000000</td>\n",
       "      <td> 564.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td> 202.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   6.200000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td>   4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope         num  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.937294  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    1.228536  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    2.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    4.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Features and convert Target to Boolean Class for Heart Disease (i.e., values 1, 2, 3 and 4 all indicate heart disease)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'age', u'sex', u'cp', u'trestbps', u'chol', u'fbs', u'restecg', u'thalach', u'exang', u'oldpeak', u'slope', u'ca', u'thal', u'num'], dtype='object')\n",
      "     age  sex  chol\n",
      "0     63    1   233\n",
      "1     67    1   286\n",
      "2     67    1   229\n",
      "3     37    1   250\n",
      "4     41    0   204\n",
      "5     56    1   236\n",
      "6     62    0   268\n",
      "7     57    0   354\n",
      "8     63    1   254\n",
      "9     53    1   203\n",
      "10    57    1   192\n",
      "11    56    0   294\n",
      "12    56    1   256\n",
      "13    44    1   263\n",
      "14    52    1   199\n",
      "15    57    1   168\n",
      "16    48    1   229\n",
      "17    54    1   239\n",
      "18    48    0   275\n",
      "19    49    1   266\n",
      "20    64    1   211\n",
      "21    58    0   283\n",
      "22    58    1   284\n",
      "23    58    1   224\n",
      "24    60    1   206\n",
      "25    50    0   219\n",
      "26    58    0   340\n",
      "27    66    0   226\n",
      "28    43    1   247\n",
      "29    40    1   167\n",
      "..   ...  ...   ...\n",
      "273   71    0   149\n",
      "274   59    1   204\n",
      "275   64    1   227\n",
      "276   66    0   278\n",
      "277   39    0   220\n",
      "278   57    1   232\n",
      "279   58    0   197\n",
      "280   57    1   335\n",
      "281   47    1   253\n",
      "282   55    0   205\n",
      "283   35    1   192\n",
      "284   61    1   203\n",
      "285   58    1   318\n",
      "286   58    0   225\n",
      "287   58    1   220\n",
      "288   56    1   221\n",
      "289   56    1   240\n",
      "290   67    1   212\n",
      "291   55    0   342\n",
      "292   44    1   169\n",
      "293   63    1   187\n",
      "294   63    0   197\n",
      "295   41    1   157\n",
      "296   59    1   176\n",
      "297   57    0   241\n",
      "298   45    1   264\n",
      "299   68    1   193\n",
      "300   57    1   131\n",
      "301   57    0   236\n",
      "302   38    1   175\n",
      "\n",
      "[303 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "heart['num'] = heart.num.map({0:0, 1:1, 2:1, 3:1, 4:1})\n",
    "print heart.columns\n",
    "print heart[['age', 'sex', 'chol']]\n",
    "#features = heart.locfeatures = heart.loc['age', 'sex', 'chol']\n",
    "\n",
    "\n",
    "#print heart.num\n",
    "\n",
    "\n",
    "#type(features)\n",
    "\n",
    "#print heart.loc[features]\n",
    "\n",
    "#print heart_features[:]\n",
    "# select feature columns (every column except for the 0th column)\n",
    "#feature_cols = vehicles.columns[1:]\n",
    "\n",
    "#print vehicles.columns\n",
    "#print feature_cols\n",
    "\n",
    "# define X (features) and y (response)\n",
    "#X = vehicles[feature_cols]\n",
    "#y = vehicles.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model and score with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How important are the various features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
